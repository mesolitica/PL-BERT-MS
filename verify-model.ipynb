{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "716f2697",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89c3fcd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "config_path = \"Configs/config.yml\"\n",
    "config = yaml.safe_load(open(config_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7771a8fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`openai-whisper` is not available, native whisper processor is not available, will use huggingface processor instead.\n"
     ]
    }
   ],
   "source": [
    "from phonemize import phonemize\n",
    "import phonemizer\n",
    "import torch\n",
    "\n",
    "global_phonemizer = phonemizer.backend.EspeakBackend(language='ms', preserve_punctuation=True,  with_stress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9bbbe379",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(config['dataset_params']['tokenizer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0ae46e38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sˈajə sˈukə mˈakan nˈasi ˈajam dan nˈasi ˈiteʔ .'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = 'saya suka makan nasi ayam dan nasi itik.'\n",
    "o = phonemize(text, global_phonemizer, tokenizer)\n",
    "phoneme = ' '.join(o['phonemes'])\n",
    "phoneme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "50d2b80b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "177\n"
     ]
    }
   ],
   "source": [
    "from text_utils import TextCleaner\n",
    "\n",
    "textcleaner = TextCleaner()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "eb8db384",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[61,\n",
       " 156,\n",
       " 43,\n",
       " 52,\n",
       " 83,\n",
       " 16,\n",
       " 61,\n",
       " 156,\n",
       " 63,\n",
       " 53,\n",
       " 83,\n",
       " 16,\n",
       " 55,\n",
       " 156,\n",
       " 43,\n",
       " 53,\n",
       " 43,\n",
       " 56,\n",
       " 16,\n",
       " 56,\n",
       " 156,\n",
       " 43,\n",
       " 61,\n",
       " 51,\n",
       " 16,\n",
       " 156,\n",
       " 43,\n",
       " 52,\n",
       " 43,\n",
       " 55,\n",
       " 16,\n",
       " 46,\n",
       " 43,\n",
       " 56,\n",
       " 16,\n",
       " 56,\n",
       " 156,\n",
       " 43,\n",
       " 61,\n",
       " 51,\n",
       " 16,\n",
       " 156,\n",
       " 51,\n",
       " 62,\n",
       " 47,\n",
       " 148,\n",
       " 16,\n",
       " 4]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_phonemes = textcleaner(phoneme)\n",
    "input_phonemes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6cc26fd5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !wget https://huggingface.co/mesolitica/PL-BERT-MS/resolve/main/step_130000.t7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "32f41b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AlbertConfig, AlbertModel\n",
    "from model import MultiTaskModel\n",
    "import pickle\n",
    "\n",
    "with open(config['dataset_params']['token_maps'], 'rb') as handle:\n",
    "    token_maps = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ea38b0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "albert_base_configuration = AlbertConfig(**config['model_params'])\n",
    "    \n",
    "bert = AlbertModel(albert_base_configuration)\n",
    "bert = MultiTaskModel(bert, \n",
    "                      num_vocab=1 + max([m['token'] for m in token_maps.values()]), \n",
    "                      num_tokens=config['model_params']['vocab_size'],\n",
    "                      hidden_size=config['model_params']['hidden_size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d59d29c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert = bert.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0daf399b",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load('step_130000.t7', map_location='cpu')\n",
    "state_dict = checkpoint['net']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e1700c8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "new_state_dict = OrderedDict()\n",
    "for k, v in state_dict.items():\n",
    "    name = k[7:]\n",
    "    new_state_dict[name] = v\n",
    "\n",
    "bert.load_state_dict(new_state_dict, strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "59d6f356",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import length_to_mask\n",
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ceda3b30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(input_phonemes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4c1d9ed7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 61, 156,  43,  52,  83,  16,  61, 156,  63,  53,  83,  16,  55, 156,\n",
       "          43,  53,  43,  56,  16,  56, 156,  43,  61,  51,  16, 156,  43,  52,\n",
       "          43,  55,  16,  46,  43,  56,  16,  56, 156,  43,  61,  51,  16, 156,\n",
       "          51,  62,  47, 148,  16,   4]], device='cuda:0')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(input_phonemes)[None].to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e33042a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "length_to_mask(torch.tensor([len(input_phonemes)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "adb6d7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_mask = length_to_mask(torch.tensor([len(input_phonemes)])).to(device)\n",
    "phonemes = torch.tensor(input_phonemes)[None].to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "65eea201",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_pred, words_pred = bert(phonemes, attention_mask=(~text_mask).int())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ebf86cb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 48, 178])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "35573d33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'word': 'saya', 'token': 759},\n",
       " {'word': 'saya', 'token': 759},\n",
       " {'word': 'saya', 'token': 759},\n",
       " {'word': 'saya', 'token': 759},\n",
       " {'word': 'saya', 'token': 759},\n",
       " {'word': '[SEP]', 'token': 2},\n",
       " {'word': 'suka', 'token': 1750},\n",
       " {'word': 'suka', 'token': 1750},\n",
       " {'word': 'suka', 'token': 1750},\n",
       " {'word': 'suka', 'token': 1750},\n",
       " {'word': 'suka', 'token': 1750},\n",
       " {'word': '[SEP]', 'token': 2},\n",
       " {'word': 'makan', 'token': 1186},\n",
       " {'word': 'makan', 'token': 1186},\n",
       " {'word': 'makan', 'token': 1186},\n",
       " {'word': 'makan', 'token': 1186},\n",
       " {'word': 'makan', 'token': 1186},\n",
       " {'word': 'makan', 'token': 1186},\n",
       " {'word': '[SEP]', 'token': 2},\n",
       " {'word': 'nasi', 'token': 1555},\n",
       " {'word': 'nasi', 'token': 1555},\n",
       " {'word': 'nasi', 'token': 1555},\n",
       " {'word': 'nasi', 'token': 1555},\n",
       " {'word': 'nasi', 'token': 1555},\n",
       " {'word': '[SEP]', 'token': 2},\n",
       " {'word': 'ayam', 'token': 1269},\n",
       " {'word': 'ayam', 'token': 1269},\n",
       " {'word': 'ayam', 'token': 1269},\n",
       " {'word': 'ayam', 'token': 1269},\n",
       " {'word': 'ayam', 'token': 1269},\n",
       " {'word': '[SEP]', 'token': 2},\n",
       " {'word': 'dan', 'token': 9},\n",
       " {'word': 'dan', 'token': 9},\n",
       " {'word': 'dan', 'token': 9},\n",
       " {'word': '[SEP]', 'token': 2},\n",
       " {'word': 'nasi', 'token': 1555},\n",
       " {'word': 'nasi', 'token': 1555},\n",
       " {'word': 'nasi', 'token': 1555},\n",
       " {'word': 'nasi', 'token': 1555},\n",
       " {'word': 'nasi', 'token': 1555},\n",
       " {'word': '[SEP]', 'token': 2},\n",
       " {'word': 'itik', 'token': 5673},\n",
       " {'word': 'itik', 'token': 5673},\n",
       " {'word': 'itik', 'token': 5673},\n",
       " {'word': 'itik', 'token': 5673},\n",
       " {'word': 'itik', 'token': 5673},\n",
       " {'word': '[SEP]', 'token': 2},\n",
       " {'word': '.', 'token': 6}]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[token_maps[int(i)] for i in words_pred.argmax(-1)[0]]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.10",
   "language": "python",
   "name": "python3.10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
